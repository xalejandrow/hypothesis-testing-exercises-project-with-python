{
"cells": [
{
"cell_type": "markdown",
"id": "d9d036c6",
"metadata": {},
"source": [
"# Hypothesis testing problem"
]
},
{
"cell_type": "markdown",
"id": "f432e18e",
"metadata": {},
"source": [
"### **Exercise 1**\n",
"\n",
"#### ANOVA\n",
"\n",
"Suppose that a study wants to check if there is a significant difference between the goal averages of soccer players depending on the position in which they play. In case there is a difference, you want to know which positions differ from the rest.\n",
"\n",
"NOTE: You must replace the values <<<FIXME>>>.\n",
"\n",
"**Exercise: Load data from \"datos_laliga.csv\". It contains a sample of randomly selected players.**"
]
},
{
"cell_type": "code",
"execution_count": null,
"id": "eecad0ca",
"metadata": {},
"outputs": [],
"source": [
"import pandas as pd\n",
"my_data = pd.read_csv(<<<FIXME>>>)\n",
"my_data"
]
},
{
"cell_type": "code",
"execution_count": null,
"id": "79e18056",
"metadata": {},
"outputs": [],
"source": [
"<<<FIXME>>>.describe()"
]
},
{
"cell_type": "markdown",
"id": "ca3da587",
"metadata": {},
"source": [
"**Exercise: Identify the number of groups and number of observations per group to determine if it is a balanced model. The mean and standard deviation of the group are also calculated.**"
]
},
{
"cell_type": "code",
"execution_count": null,
"id": "9ce74972",
"metadata": {},
"outputs": [],
"source": [
"pd.crosstab(my_data[<<<FIXME>>>],columns=[\"DC\", \"MO\", \"MP\", \"P\"])\n",
"#DC: Delantero centro\n",
"#MO: Medio ofensivo\n",
"#MP: Media punta\n",
"#P: Puntero"
]
},
{
"cell_type": "markdown",
"id": "099d82f4",
"metadata": {},
"source": [
"**Exercise: Calculate the mean and standar deviation by position**"
]
},
{
"cell_type": "code",
"execution_count": null,
"id": "ad59e5a5",
"metadata": {},
"outputs": [],
"source": [
"my_data.groupby('<<<FIXME>>>')['average'].agg('<<<FIXME>>>')"
]
},
{
"cell_type": "markdown",
"id": "ca409b23",
"metadata": {},
"source": [
"**Exercise: Calculate the standard deviation by position**"
]
},
{
"cell_type": "code",
"execution_count": null,
"id": "edba4764",
"metadata": {},
"outputs": [],
"source": [
"\n",
"my_data.groupby('<<<FIXME>>>')['average'].agg('<<<FIXME>>>')"
]
},
{
"cell_type": "markdown",
"id": "2a3c9e4b",
"metadata": {},
"source": [
"Since the number of observations per group is not constant, it is an unbalanced model. It is important to take this into account when checking the conditions of normality and homoscedasticity (s1 = s2 = s3 = s4). The most useful graphical representation before performing an ANOVA is the Box-Plot model.\n",
"\n",
"**Exercise: Plot a boxplot for each position**"
]
},
{
"cell_type": "code",
"execution_count": null,
"id": "efab02f8",
"metadata": {},
"outputs": [],
"source": [
"# Boxplots\n",
"# This is another way and popular package used in R (ggplot)\n",
"from plotnine import *\n",
"\n",
"(\n",
"    ggplot(my_data)  # What data to use\n",
"    + aes(x=\"<<<FIXME>>>\", y=\"average\")  # What variable to use\n",
"    + geom_boxplot()  # Geometric object to use for drawing\n",
"    + theme_bw()\n",
")"
]
},
{
"cell_type": "markdown",
"id": "066d7248",
"metadata": {},
"source": [
"#### Independence\n",
"\n",
"The total sample size is <10% of the population of all players in the league. The groups (categorical variable) are independent of each other since a random sample of players from the entire league (not just from the same team) has been made.\n",
"\n",
"Normal distribution of observations: The quantitative variable must be distributed in a normal way in each of the groups. The normality study can be done graphically (qqplot) or with a hypothesis test.\n",
"\n",
"**Exercise: Make an analysis about normal distribution for each position**"
]
},
{
"cell_type": "code",
"execution_count": null,
"id": "adac09ca",
"metadata": {},
"outputs": [],
"source": [
"import numpy as np \n",
"import pylab \n",
"import matplotlib.pyplot as plt\n",
"import scipy.stats as stats\n",
"\n",
"measurements = my_data.loc[my_data[\"<<<FIXME>>>\"] == \"<<<FIXME>>>\",\"average\"]\n",
"stats.probplot(measurements, dist=\"norm\", plot=pylab)\n",
"plt.title(\"P\")\n",
"plt.show()\n",
"\n",
"measurements = my_data.loc[my_data[\"<<<FIXME>>>\"] == \"<<<FIXME>>>\",\"average\"]\n",
"stats.probplot(measurements, dist=\"norm\", plot=pylab)\n",
"plt.title(\"MO\")\n",
"plt.show()\n",
"\n",
"measurements = my_data.loc[my_data[\"<<<FIXME>>>\"] == \"<<<FIXME>>>\",\"average\"]\n",
"stats.probplot(measurements, dist=\"norm\", plot=pylab)\n",
"plt.title(\"DC\")\n",
"plt.show()\n",
"\n",
"measurements = my_data.loc[my_data[\"<<<FIXME>>>\"] == \"<<<FIXME>>>\",\"average\"]\n",
"stats.probplot(measurements, dist=\"norm\", plot=pylab)\n",
"plt.title(\"MP\")\n",
"plt.show()"
]
},
{
"cell_type": "markdown",
"id": "e329928e",
"metadata": {},
"source": [
"**Exercise: make the boxplot for each position, what you can say about them?**"
]
},
{
"cell_type": "code",
"execution_count": null,
"id": "13a89420",
"metadata": {},
"outputs": [],
"source": [
"# Using plotly\n",
"import plotly.graph_objects as go\n",
"\n",
"fig = go.Figure()\n",
"fig.add_trace(go.Box(y=my_data.loc[my_data[\"<<<FIXME>>>\"] == \"<<<FIXME>>>\",\"average\"]))\n",
"fig.add_trace(go.Box(y=my_data.loc[my_data[\"<<<FIXME>>>\"] == \"<<<FIXME>>>\",\"average\"]))\n",
"fig.add_trace(go.Box(y=my_data.loc[my_data[\"<<<FIXME>>>\"] == \"<<<FIXME>>>\",\"average\"]))\n",
"fig.add_trace(go.Box(y=my_data.loc[my_data[\"<<<FIXME>>>\"] == \"<<<FIXME>>>\",\"average\"]))\n",
"fig.show()"
]
},
{
"cell_type": "markdown",
"id": "6b975d51",
"metadata": {},
"source": [
"**Exercise: Use the Kolmogorov-Smirnov test or with or without the Lilliefors correction in order to know the normality distribution.**"
]
},
{
"cell_type": "code",
"execution_count": null,
"id": "49c1e3f4",
"metadata": {},
"outputs": [],
"source": [
"# Beginner way to do it\n",
"\n",
"from statsmodels.stats.diagnostic import lilliefors\n",
"\n",
"my_df = pd.DataFrame(index=np.arange(len(np.unique(my_data[\"position\"]))), columns=[\"position\", \"D_statistic\", \"p_value\"])\n",
"my_df[\"position\"] = np.unique(my_data[\"position\"])\n",
"\n",
"for position in my_df[\"position\"]:\n",
"    my_data_subset = my_data.loc[my_data[\"position\"] == position,:]\n",
"    D_statistic, p_value = lilliefors(my_data_subset.average)\n",
"    my_df.loc[my_df[\"position\"]==position,[\"D_statistic\", \"p_value\"]] = D_statistic, p_value\n",
"    \n",
"print(my_df)"
]
},
{
"cell_type": "code",
"execution_count": null,
"id": "860961af",
"metadata": {},
"outputs": [],
"source": [
"#Another way to do it (Highly recommendable)\n",
"my_data.groupby(\"<<<FIXME>>>\")[\"average\"].apply(<<<FIXME>>>)"
]
},
{
"cell_type": "markdown",
"id": "e7e9481f",
"metadata": {},
"source": [
"The hypothesis tests do not show evidence of a lack of normality.\n",
"\n",
"Constant variance between groups (homoscedasticity):\n",
"\n",
"Given that there is a group (DC) that is at the limit to accept that it is distributed in a normal way, the Fisher and Bartlett tests are not recommended. Instead it is better to use a test based on the median Levene test or the Fligner-Killeen test.\n",
"\n",
"**Exercise: use the fligner and levene functions from scipy.stats in order to know the homocedasticy**"
]
},
{
"cell_type": "code",
"execution_count": null,
"id": "c482b792",
"metadata": {},
"outputs": [],
"source": [
"from scipy import stats\n",
"\n",
"values_array = pd.DataFrame(my_data.groupby(\"<<<FIXME>>>\")[\"average\"]).to_numpy()\n",
"\n",
"print(stats.fligner(values_array[0,1], values_array[1,1], values_array[2,1], values_array[3,1]))\n",
"\n",
"print(stats.levene(values_array[0,1], values_array[1,1], values_array[2,1], values_array[3,1]))\n",
"\n",
"# stats.fligner(values_array[:,1]) # It doesn't work, please analyse"
]
},
{
"cell_type": "markdown",
"id": "26789016",
"metadata": {},
"source": [
"There is no significant evidence of lack of homoscedasticity in either of the two tests.\n",
"\n",
"The study of the conditions can be carried out after calculating the ANOVA, since if they are not fulfilled, it does not make much sense to continue. However, the most appropriate way to verify that the necessary conditions are satisfied is by studying the model residuals once the ANOVA has been generated.\n",
"\n",
"**Exercise: make an ANOVA table and analyze the p-value using the packages statsmodels and the bioinfokit**"
]
},
{
"cell_type": "code",
"execution_count": null,
"id": "e1213d0d",
"metadata": {},
"outputs": [],
"source": [
"# get ANOVA table as R like output\n",
"import statsmodels.api as sm\n",
"from statsmodels.formula.api import ols\n",
"\n",
"# Ordinary Least Squares (OLS) model\n",
"model = ols('<<<FIXME>>> ~ <<<FIXME>>>', data=my_data).fit()\n",
"anova_table = sm.stats.anova_lm(model, typ=2)\n",
"anova_table"
]
},
{
"cell_type": "code",
"execution_count": null,
"id": "02ff57d2",
"metadata": {},
"outputs": [],
"source": [
"# ANOVA with package bioinfokit\n",
"from bioinfokit.analys import stat\n",
"res = stat()\n",
"res.anova_stat(df=my_data, res_var='value', anova_model='<<<FIXME>>> ~ <<<FIXME>>>')\n",
"res.anova_summary\n",
"# output (ANOVA F and p value)"
]
},
{
"cell_type": "markdown",
"id": "37b96c48",
"metadata": {},
"source": [
"**Exercise: make a plot of the fitted values vs residuals. Make the plot of the Standardized Residuals. Make the histogram of the residuals.**"
]
},
{
"cell_type": "code",
"execution_count": null,
"id": "d4985e5b",
"metadata": {},
"outputs": [],
"source": [
"# QQ-plot\n",
"import statsmodels.api as sm\n",
"import matplotlib.pyplot as plt\n",
"\n",
"\n",
"plt.scatter(res.anova_model_out.<<<FIXME>>>, res.anova_model_out.<<<FIXME>>>)\n",
"plt.xlabel(\"Fitted values\")\n",
"plt.ylabel(\"Residuals\")\n",
"plt.title(\"Residuals vs. Fitted\")\n",
"plt.show()\n",
"\n",
"# res.anova_std_residuals are standardized residuals obtained from ANOVA (check above)\n",
"sm.qqplot(res.<<<FIXME>>>, line='45')\n",
"plt.xlabel(\"Theoretical Quantiles\")\n",
"plt.ylabel(\"Standardized Residuals\")\n",
"plt.show()\n",
"\n",
"# histogram\n",
"plt.hist(res.anova_model_out.<<<FIXME>>>, bins='auto', histtype='bar', ec='k') \n",
"plt.xlabel(\"Residuals\")\n",
"plt.ylabel('Frequency')\n",
"plt.show()"
]
},
{
"cell_type": "markdown",
"id": "95374b26",
"metadata": {},
"source": [
"Given that the p-value is higher than 0.05, there is not enough evidence to consider that at least two means are different. The graphical representation of the residuals does not show lack of homoscedasticity (graph 1) and in the qqplot the residuals are distributed very close to the normal line (graph 2 and 3)."
]
},
{
"cell_type": "markdown",
"id": "7d4d17f5",
"metadata": {},
"source": [
"### **Exercise 2**\n",
"\n",
"#### T-TEST INDEPENDENT\n",
"\n",
"A professor gives online lectures. Later, he uploads recorded lectures to the cloud for students who followed the course asynchronously (those who did not attend the lesson but later watched the records). However, he believes that the students who attend class at the class time and participate in the process are more successful. Therefore, he recorded the average grades of the students at the end of the semester. The data is below.\n",
"\n",
"```py\n",
"synchronous = [94. , 84.9, 82.6, 69.5, 80.1, 79.6, 81.4, 77.8, 81.7, 78.8, 73.2, 87.9, 87.9, 93.5, 82.3, 79.3, 78.3, 71.6, 88.6, 74.6, 74.1, 80.6]\n",
"\n",
"\n",
"asynchronous = [77.1, 71.7, 91. , 72.2, 74.8, 85.1, 67.6, 69.9, 75.3, 71.7, 65.7, 72.6, 71.5, 78.2]\n",
"```\n",
"\n",
"Conduct the hypothesis testing to check whether the professor’s belief is statistically significant by using a 0.05 significance level to evaluate the null and alternative hypotheses. Before doing hypothesis testing, check the related assumptions. Comment on the results."
]
},
{
"cell_type": "markdown",
"id": "eee68c9e",
"metadata": {},
"source": [
"**1. Defining Hypothesis**\n",
"\n",
"H₀: μₛ≤μₐ\n",
"\n",
"H₁: μₛ>μₐ"
]
},
{
"cell_type": "markdown",
"id": "d58ab5cf",
"metadata": {},
"source": [
"**2. Assumption Check**\n",
"\n",
"H₀: The data is normally distributed.\n",
"\n",
"H₁: The data is not normally distributed.\n",
"\n",
"Assume that α=0.05. If the p-value is >0.05, it can be said that data is normally distributed."
]
},
{
"cell_type": "code",
"execution_count": 5,
"id": "659b8de9",
"metadata": {},
"outputs": [],
"source": [
"# import libraries"
]
},
{
"cell_type": "code",
"execution_count": 1,
"id": "aecea0ff",
"metadata": {},
"outputs": [],
"source": [
"def check_normality(data):\n",
"    test_stat_normality, p_value_normality=stats.shapiro(data)\n",
"    print(\"p value:%.4f\" % p_value_normality)\n",
"    if p_value_normality <0.05:\n",
"        print(\"Reject null hypothesis >> The data is not normally distributed\")\n",
"    else:\n",
"        print(\"Fail to reject null hypothesis >> The data is normally distributed\")    "
]
},
{
"cell_type": "code",
"execution_count": 1,
"id": "a44102f4",
"metadata": {},
"outputs": [],
"source": [
"#define veriables"
]
},
{
"cell_type": "code",
"execution_count": null,
"id": "38ed026b",
"metadata": {},
"outputs": [],
"source": [
"#check normality"
]
},
{
"cell_type": "markdown",
"id": "bf59816a",
"metadata": {},
"source": [
"H₀: The variances of the samples are the same.\n",
"\n",
"H₁: The variances of the samples are different."
]
},
{
"cell_type": "code",
"execution_count": 2,
"id": "9072d157",
"metadata": {},
"outputs": [],
"source": [
"def check_variance_homogeneity(group1, group2):\n",
"    test_stat_var, p_value_var= stats.levene(group1,group2)\n",
"    print(\"p value:%.4f\" % p_value_var)\n",
"    if p_value_var <0.05:\n",
"        print(\"Reject null hypothesis >> The variances of the samples are different.\")\n",
"    else:\n",
"        print(\"Fail to reject null hypothesis >> The variances of the samples are same.\")\n"
]
},
{
"cell_type": "markdown",
"id": "fdc87982",
"metadata": {},
"source": [
"It tests the null hypothesis that the population variances are equal (called homogeneity of variance or homoscedasticity). Suppose the resulting p-value of Levene’s test is less than the significance level (typically 0.05). In that case, the obtained differences in sample variances are unlikely to have occurred based on random sampling from a population with equal variances."
]
},
{
"cell_type": "code",
"execution_count": null,
"id": "a398af0c",
"metadata": {},
"outputs": [],
"source": [
"#check_variance_homogeneity"
]
},
{
"cell_type": "markdown",
"id": "e92eef87",
"metadata": {},
"source": [
"Are assumptions satisfied?"
]
},
{
"cell_type": "code",
"execution_count": null,
"id": "f4211536",
"metadata": {},
"outputs": [],
"source": [
"#perform the parametric version of the test for 2 groups and unpaired data."
]
},
{
"cell_type": "markdown",
"id": "228631a1",
"metadata": {},
"source": [
"Macke a conclusion"
]
}
],
"metadata": {
"interpreter": {
"hash": "9248718ffe6ce6938b217e69dbcc175ea21f4c6b28a317e96c05334edae734bb"
},
"kernelspec": {
"display_name": "Python 3.9.12 ('ML-BOOTCAMP')",
"language": "python",
"name": "python3"
},
"language_info": {
"codemirror_mode": {
"name": "ipython",
"version": 3
},
"file_extension": ".py",
"mimetype": "text/x-python",
"name": "python",
"nbconvert_exporter": "python",
"pygments_lexer": "ipython3",
"version": "3.9.12"
}
},
"nbformat": 4,
"nbformat_minor": 5
}
